import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
from pathlib import Path
import warnings
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum

warnings.filterwarnings('ignore')


class ValidationLevel(Enum):
    """N√≠veis de valida√ß√£o do sistema."""
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"


@dataclass
class ValidationResult:
    """Resultado de uma valida√ß√£o espec√≠fica."""
    level: ValidationLevel
    message: str
    count: int = 0
    details: Optional[str] = None


@dataclass
class ProcessingStats:
    """Estat√≠sticas do processamento."""
    total_collaborators: int
    total_days: int
    total_value: float
    company_cost: float
    professional_discount: float
    excluded_count: int
    processing_time: float


class DataLoader:
    """Classe respons√°vel pelo carregamento de dados."""
    
    FILE_MAPPING = {
        'admissao': 'ADMISS√ÉO ABRIL.xlsx',
        'afastamentos': 'AFASTAMENTOS.xlsx',
        'aprendiz': 'APRENDIZ.xlsx',
        'ativos': 'ATIVOS.xlsx',
        'dias_uteis': 'Base dias uteis.xlsx',
        'sindicato_valor': 'Base sindicato x valor.xlsx',
        'desligados': 'DESLIGADOS.xlsx',
        'estagio': 'EST√ÅGIO.xlsx',
        'exterior': 'EXTERIOR.xlsx',
        'ferias': 'F√âRIAS.xlsx'
    }
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.loaded_data = {}
        self.failed_files = []
        
    def load_all_data(self, files_folder: str) -> Dict[str, pd.DataFrame]:
        """Carrega todas as bases de dados necess√°rias."""
        self.logger.info("üìÅ Iniciando carregamento das bases de dados...")
        
        files_folder = Path(files_folder)
        
        if not files_folder.exists():
            raise FileNotFoundError(f"Pasta de dados n√£o encontrada: {files_folder}")
        
        for name, filename in self.FILE_MAPPING.items():
            file_path = files_folder / filename
            
            try:
                if file_path.exists():
                    df = pd.read_excel(file_path)
                    self.loaded_data[name] = df
                    self.logger.info(f"  ‚úÖ {filename}: {len(df)} registros carregados")
                else:
                    self.logger.warning(f"  ‚ö†Ô∏è  {filename}: arquivo n√£o encontrado")
                    self.failed_files.append(filename)
                    
            except Exception as e:
                self.logger.error(f"  ‚ùå Erro ao carregar {filename}: {str(e)}")
                self.failed_files.append(filename)
        
        self._validate_essential_files()
        return self.loaded_data
    
    def _validate_essential_files(self) -> None:
        """Valida se arquivos essenciais foram carregados."""
        essential_files = ['ativos', 'sindicato_valor', 'dias_uteis']
        missing_essential = [f for f in essential_files if f not in self.loaded_data]
        
        if missing_essential:
            raise ValueError(f"Arquivos essenciais n√£o encontrados: {missing_essential}")


class DataProcessor:
    """Classe respons√°vel pelo processamento e limpeza de dados."""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        
    def clean_and_standardize(self, data: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:
        """Limpa e padroniza os dados das bases."""
        self.logger.info("üßπ Iniciando limpeza e padroniza√ß√£o dos dados...")
        
        # Padronizar colunas MATRICULA
        matricula_files = ['admissao', 'afastamentos', 'aprendiz', 'ativos', 'desligados', 'estagio', 'ferias']
        
        for name in matricula_files:
            if name in data and 'MATRICULA' in data[name].columns:
                data[name]['MATRICULA'] = (
                    data[name]['MATRICULA']
                    .astype(str)
                    .str.strip()
                    .str.upper()
                )
        
        # Tratar arquivo exterior (coluna diferente)
        if 'exterior' in data and 'MATRICULA' in data['exterior'].columns:
            data['exterior']['MATRICULA'] = (
                data['exterior']['MATRICULA']
                .astype(str)
                .str.strip()
                .str.upper()
            )
        
        # Converter e validar datas
        self._process_dates(data)
        
        # Padronizar nomes de sindicatos
        self._standardize_union_names(data)
        
        self.logger.info("  ‚úÖ Dados limpos e padronizados com sucesso")
        return data
    
    def _process_dates(self, data: Dict[str, pd.DataFrame]) -> None:
        """Processa e valida campos de data."""
        date_conversions = [
            ('admissao', 'Admiss√£o'),
            ('desligados', 'DATA DEMISS√ÉO')
        ]
        
        for file_key, column_name in date_conversions:
            if file_key in data and column_name in data[file_key].columns:
                original_count = len(data[file_key])
                data[file_key][column_name] = pd.to_datetime(
                    data[file_key][column_name], 
                    errors='coerce',
                    dayfirst=True
                )
                
                invalid_dates = data[file_key][column_name].isna().sum()
                if invalid_dates > 0:
                    self.logger.warning(
                        f"  ‚ö†Ô∏è  {file_key}.{column_name}: {invalid_dates}/{original_count} datas inv√°lidas"
                    )
    
    def _standardize_union_names(self, data: Dict[str, pd.DataFrame]) -> None:
        """Padroniza nomes de sindicatos."""
        union_files = ['ativos']
        
        for file_key in union_files:
            if file_key in data and 'SINDICATO' in data[file_key].columns:
                data[file_key]['SINDICATO'] = (
                    data[file_key]['SINDICATO']
                    .astype(str)
                    .str.strip()
                    .str.upper()
                )


class ExclusionManager:
    """Gerencia exclus√µes de colaboradores."""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.exclusion_details = {}
        
    def identify_exclusions(self, data: Dict[str, pd.DataFrame]) -> set:
        """Identifica todas as matr√≠culas a serem exclu√≠das."""
        self.logger.info("üö´ Identificando exclus√µes por categoria...")
        
        all_exclusions = set()
        
        exclusion_rules = [
            ('directors', self._get_directors),
            ('interns', self._get_interns),
            ('apprentices', self._get_apprentices),
            ('away', self._get_away),
            ('exterior', self._get_exterior)
        ]
        
        for category, rule_func in exclusion_rules:
            excluded = rule_func(data)
            self.exclusion_details[category] = excluded
            all_exclusions.update(excluded)
            self.logger.info(f"  üìä {category.title()}: {len(excluded)} exclus√µes")
        
        self.logger.info(f"  üéØ Total de exclus√µes √∫nicas: {len(all_exclusions)}")
        return all_exclusions
    
    def _get_directors(self, data: Dict[str, pd.DataFrame]) -> set:
        """Identifica diretores pelo cargo."""
        if 'ativos' not in data:
            return set()
            
        directors_mask = (
            data['ativos']['TITULO DO CARGO']
            .str.contains('DIRETOR', case=False, na=False)
        )
        return set(data['ativos'][directors_mask]['MATRICULA'].tolist())
    
    def _get_interns(self, data: Dict[str, pd.DataFrame]) -> set:
        """Identifica estagi√°rios."""
        if 'estagio' not in data:
            return set()
        return set(data['estagio']['MATRICULA'].tolist())
    
    def _get_apprentices(self, data: Dict[str, pd.DataFrame]) -> set:
        """Identifica aprendizes."""
        if 'aprendiz' not in data:
            return set()
        return set(data['aprendiz']['MATRICULA'].tolist())
    
    def _get_away(self, data: Dict[str, pd.DataFrame]) -> set:
        """Identifica afastados."""
        if 'afastamentos' not in data:
            return set()
        return set(data['afastamentos']['MATRICULA'].tolist())
    
    def _get_exterior(self, data: Dict[str, pd.DataFrame]) -> set:
        """Identifica colaboradores no exterior."""
        if 'exterior' not in data:
            return set()
        return set(data['exterior']['MATRICULA'].tolist())


class CalculationEngine:
    """Motor de c√°lculos para VR."""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.business_days_mapping = {}
        self.daily_values_mapping = {}
        
    def prepare_calculation_data(self, data: Dict[str, pd.DataFrame]) -> None:
        """Prepara dados para c√°lculos."""
        self._build_business_days_mapping(data)
        self._build_daily_values_mapping(data)
    
    def _build_business_days_mapping(self, data: Dict[str, pd.DataFrame]) -> None:
        """Constr√≥i mapeamento de dias √∫teis por sindicato."""
        if 'dias_uteis' not in data:
            self.logger.warning("  ‚ö†Ô∏è  Base de dias √∫teis n√£o encontrada, usando padr√£o de 22 dias")
            return
            
        for _, row in data['dias_uteis'].iterrows():
            union = str(row['SINDICATO']).strip().upper()
            days = int(row['DIAS UTEIS']) if pd.notna(row['DIAS UTEIS']) else 22
            self.business_days_mapping[union] = days
            
        self.logger.info(f"  üìä Mapeamento de dias √∫teis: {len(self.business_days_mapping)} sindicatos")
    
    def _build_daily_values_mapping(self, data: Dict[str, pd.DataFrame]) -> None:
        """Constr√≥i mapeamento de valores di√°rios por estado."""
        if 'sindicato_valor' not in data:
            self.logger.warning("  ‚ö†Ô∏è  Base de valores n√£o encontrada, usando padr√£o R$ 35,00")
            return
            
        for _, row in data['sindicato_valor'].iterrows():
            state = str(row['ESTADO']).strip().upper()
            value_str = str(row['VALOR']).replace('R$', '').replace(' ', '').replace(',', '.')
            
            try:
                value = float(value_str)
                self.daily_values_mapping[state] = value
            except ValueError:
                self.logger.warning(f"  ‚ö†Ô∏è  Valor inv√°lido para estado {state}: {row['VALOR']}")
                
        self.logger.info(f"  üìä Mapeamento de valores: {len(self.daily_values_mapping)} estados")
    
    def calculate_days_worked(self, 
                            base_days: int,
                            vacation_days: int,
                            admission_date: Optional[datetime],
                            dismissal_date: Optional[datetime],
                            competence_month: int,
                            competence_year: int) -> int:
        """Calcula dias trabalhados considerando todas as regras."""
        
        days_worked = base_days - vacation_days
        
        # Ajuste para admiss√£o no meio do m√™s
        if (admission_date and 
            admission_date.month == competence_month and 
            admission_date.year == competence_year):
            
            remaining_days = 30 - admission_date.day + 1
            proportion = remaining_days / 30
            days_worked = int(base_days * proportion)
        
        # Ajuste para demiss√£o proporcional
        if (dismissal_date and 
            dismissal_date.month == competence_month and 
            dismissal_date.year == competence_year):
            
            worked_days_month = dismissal_date.day
            proportion = worked_days_month / 30
            days_worked = int(base_days * proportion)
        
        return max(0, days_worked)
    
    def get_daily_value(self, union_name: str) -> float:
        """Obt√©m valor di√°rio baseado no sindicato/estado."""
        union_upper = union_name.upper()
        
        for state, value in self.daily_values_mapping.items():
            if state in union_upper:
                return value
                
        return 35.0  # Valor padr√£o


class DataValidator:
    """Validador de dados processados."""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        
    def validate_processed_data(self, df: pd.DataFrame) -> List[ValidationResult]:
        """Executa todas as valida√ß√µes nos dados processados."""
        self.logger.info("üîç Executando valida√ß√µes dos dados processados...")
        
        validations = []
        
        # Valida√ß√£o 1: Dias negativos
        validations.append(self._validate_negative_days(df))
        
        # Valida√ß√£o 2: Valores inconsistentes
        validations.append(self._validate_value_consistency(df))
        
        # Valida√ß√£o 3: Rateio empresa/profissional
        validations.append(self._validate_cost_split(df))
        
        # Valida√ß√£o 4: Matr√≠culas duplicadas
        validations.append(self._validate_duplicate_registrations(df))
        
        # Valida√ß√£o 5: Valores extremos
        validations.append(self._validate_extreme_values(df))
        
        # Valida√ß√£o 6: Dados obrigat√≥rios
        validations.append(self._validate_required_fields(df))
        
        return validations
    
    def _validate_negative_days(self, df: pd.DataFrame) -> ValidationResult:
        """Valida se h√° dias negativos."""
        negative_count = len(df[df['Dias'] < 0])
        
        if negative_count > 0:
            return ValidationResult(
                level=ValidationLevel.ERROR,
                message="Registros com dias negativos encontrados",
                count=negative_count,
                details="Verifique c√°lculos de f√©rias e admiss√µes"
            )
        
        return ValidationResult(
            level=ValidationLevel.INFO,
            message="Todos os registros t√™m dias v√°lidos",
            count=0
        )
    
    def _validate_value_consistency(self, df: pd.DataFrame) -> ValidationResult:
        """Valida consist√™ncia entre dias e valores."""
        inconsistent = df[
            (df['Dias'] > 0) & (df['TOTAL'] <= 0)
        ]
        count = len(inconsistent)
        
        if count > 0:
            return ValidationResult(
                level=ValidationLevel.ERROR,
                message="Registros com dias > 0 mas valor = 0",
                count=count,
                details="Verifique mapeamento de valores por estado"
            )
        
        return ValidationResult(
            level=ValidationLevel.INFO,
            message="Valores consistentes com dias trabalhados",
            count=0
        )
    
    def _validate_cost_split(self, df: pd.DataFrame) -> ValidationResult:
        """Valida se o rateio empresa/profissional est√° correto."""
        tolerance = 0.01
        incorrect_split = df[
            abs(df['Custo empresa'] + df['Desconto profissional'] - df['TOTAL']) > tolerance
        ]
        count = len(incorrect_split)
        
        if count > 0:
            return ValidationResult(
                level=ValidationLevel.ERROR,
                message="Diverg√™ncias no rateio empresa/profissional",
                count=count,
                details="Soma dos valores n√£o corresponde ao total"
            )
        
        return ValidationResult(
            level=ValidationLevel.INFO,
            message="Rateio empresa/profissional correto",
            count=0
        )
    
    def _validate_duplicate_registrations(self, df: pd.DataFrame) -> ValidationResult:
        """Valida matr√≠culas duplicadas."""
        total_records = len(df)
        unique_records = df['Matricula'].nunique()
        duplicates = total_records - unique_records
        
        if duplicates > 0:
            return ValidationResult(
                level=ValidationLevel.ERROR,
                message="Matr√≠culas duplicadas encontradas",
                count=duplicates,
                details="Verifique processamento de dados base"
            )
        
        return ValidationResult(
            level=ValidationLevel.INFO,
            message="Todas as matr√≠culas s√£o √∫nicas",
            count=0
        )
    
    def _validate_extreme_values(self, df: pd.DataFrame) -> ValidationResult:
        """Valida valores extremos (muito altos ou baixos)."""
        # Considera valores extremos: > R$ 3000 ou dias > 30
        extreme_values = df[
            (df['TOTAL'] > 3000) | (df['Dias'] > 30)
        ]
        count = len(extreme_values)
        
        if count > 0:
            return ValidationResult(
                level=ValidationLevel.WARNING,
                message="Valores extremos detectados",
                count=count,
                details="Verifique se os c√°lculos est√£o corretos"
            )
        
        return ValidationResult(
            level=ValidationLevel.INFO,
            message="Valores dentro da faixa esperada",
            count=0
        )
    
    def _validate_required_fields(self, df: pd.DataFrame) -> ValidationResult:
        """Valida campos obrigat√≥rios."""
        required_fields = ['Matricula', 'Sindicato do Colaborador', 'Compet√™ncia']
        
        missing_data = 0
        for field in required_fields:
            if field in df.columns:
                missing_data += df[field].isna().sum()
        
        if missing_data > 0:
            return ValidationResult(
                level=ValidationLevel.WARNING,
                message="Dados obrigat√≥rios ausentes",
                count=missing_data,
                details=f"Campos verificados: {', '.join(required_fields)}"
            )
        
        return ValidationResult(
            level=ValidationLevel.INFO,
            message="Todos os campos obrigat√≥rios preenchidos",
            count=0
        )


class VRAutomation:
    """Classe principal do sistema de automa√ß√£o VR."""
    
    def __init__(self):
        self.logger = self._setup_logger()
        self.data_loader = DataLoader(self.logger)
        self.data_processor = DataProcessor(self.logger)
        self.exclusion_manager = ExclusionManager(self.logger)
        self.calculation_engine = CalculationEngine(self.logger)
        self.validator = DataValidator(self.logger)
        
        self.raw_data = {}
        self.processed_data = {}
        self.final_result = None
        self.processing_stats = None
        
    def _setup_logger(self) -> logging.Logger:
        """Configura logger espec√≠fico para VR Automation."""
        logger = logging.getLogger('VRAutomation')
        
        if not logger.handlers:  # Evita duplica√ß√£o de handlers
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
            
        return logger
    
    def load_data(self, files_folder: str) -> Dict[str, pd.DataFrame]:
        """Carrega todas as bases de dados."""
        self.raw_data = self.data_loader.load_all_data(files_folder)
        return self.raw_data
    
    def process_data(self) -> Dict[str, pd.DataFrame]:
        """Processa e limpa os dados carregados."""
        if not self.raw_data:
            raise ValueError("Dados n√£o carregados. Execute load_data() primeiro.")
            
        self.processed_data = self.data_processor.clean_and_standardize(self.raw_data)
        return self.processed_data
    
    def create_consolidated_base(self, competence_month: int = 5, competence_year: int = 2025) -> pd.DataFrame:
        """Cria a base consolidada final com todos os c√°lculos."""
        start_time = datetime.now()
        
        self.logger.info(f"üîÑ Criando base consolidada para {competence_month:02d}/{competence_year}...")
        
        if not self.processed_data:
            raise ValueError("Dados n√£o processados. Execute process_data() primeiro.")
        
        # Preparar dados de c√°lculo
        self.calculation_engine.prepare_calculation_data(self.processed_data)
        
        # Base principal: colaboradores ativos
        if 'ativos' not in self.processed_data:
            raise ValueError("Base de colaboradores ativos n√£o encontrada!")
        
        base_final = self.processed_data['ativos'][
            ['MATRICULA', 'TITULO DO CARGO', 'DESC. SITUACAO', 'SINDICATO']
        ].copy()
        
        # Adicionar informa√ß√µes complementares
        base_final = self._enrich_base_data(base_final)
        
        # Aplicar exclus√µes
        exclusions = self.exclusion_manager.identify_exclusions(self.processed_data)
        initial_count = len(base_final)
        base_final = base_final[~base_final['MATRICULA'].isin(exclusions)]
        excluded_count = initial_count - len(base_final)
        
        self.logger.info(f"  üìä Ap√≥s exclus√µes: {len(base_final)} colaboradores eleg√≠veis")
        
        # Aplicar regras de elegibilidade
        base_final = self._apply_eligibility_rules(base_final)
        
        # Gerar registros finais com c√°lculos
        results = self._generate_final_records(base_final, competence_month, competence_year)
        
        self.final_result = pd.DataFrame(results)
        
        # Calcular estat√≠sticas
        processing_time = (datetime.now() - start_time).total_seconds()
        self.processing_stats = ProcessingStats(
            total_collaborators=len(self.final_result),
            total_days=self.final_result['Dias'].sum(),
            total_value=self.final_result['TOTAL'].sum(),
            company_cost=self.final_result['Custo empresa'].sum(),
            professional_discount=self.final_result['Desconto profissional'].sum(),
            excluded_count=excluded_count,
            processing_time=processing_time
        )
        
        self.logger.info(f"  ‚úÖ Base consolidada criada: {len(self.final_result)} registros")
        self.logger.info(f"  ‚è±Ô∏è  Tempo de processamento: {processing_time:.2f}s")
        
        return self.final_result
    
    def _enrich_base_data(self, base_df: pd.DataFrame) -> pd.DataFrame:
        """Enriquece dados base com informa√ß√µes complementares."""
        # Adicionar admiss√µes
        if 'admissao' in self.processed_data:
            admissions = self.processed_data['admissao'][['MATRICULA', 'Admiss√£o']].copy()
            base_df = base_df.merge(admissions, on='MATRICULA', how='left')
        
        # Adicionar f√©rias
        base_df['Dias_Ferias'] = 0
        if 'ferias' in self.processed_data:
            holidays_dict = dict(zip(
                self.processed_data['ferias']['MATRICULA'], 
                self.processed_data['ferias']['DIAS DE F√âRIAS'].fillna(0)
            ))
            base_df['Dias_Ferias'] = base_df['MATRICULA'].map(holidays_dict).fillna(0)
        
        # Adicionar informa√ß√µes de desligamento
        base_df['Data_Demissao'] = None
        base_df['Comunicado_Desligamento'] = None
        
        if 'desligados' in self.processed_data:
            disconnected_info = self.processed_data['desligados'].set_index('MATRICULA')
            
            for idx, row in base_df.iterrows():
                matricula = row['MATRICULA']
                if matricula in disconnected_info.index:
                    base_df.at[idx, 'Data_Demissao'] = disconnected_info.loc[matricula, 'DATA DEMISS√ÉO']
                    base_df.at[idx, 'Comunicado_Desligamento'] = disconnected_info.loc[matricula, 'COMUNICADO DE DESLIGAMENTO']
        
        return base_df
    
    def _apply_eligibility_rules(self, base_df: pd.DataFrame) -> pd.DataFrame:
        """Aplica regras de elegibilidade para pagamento."""
        base_df['Elegivel_Pagamento'] = True
        
        # Regra de desligamento: se desligado at√© dia 15 com comunicado OK, n√£o paga
        mask_dismissal = (
            (base_df['Comunicado_Desligamento'] == 'OK') &
            (pd.notna(base_df['Data_Demissao'])) &
            (base_df['Data_Demissao'].dt.day <= 15)
        )
        
        base_df.loc[mask_dismissal, 'Elegivel_Pagamento'] = False
        ineligible_count = mask_dismissal.sum()
        
        if ineligible_count > 0:
            self.logger.info(f"  üìä Colaboradores ineleg√≠veis por regra de desligamento: {ineligible_count}")
        
        return base_df[base_df['Elegivel_Pagamento'] == True]
    
    def _generate_final_records(self, base_df: pd.DataFrame, competence_month: int, competence_year: int) -> List[Dict]:
        """Gera registros finais com todos os c√°lculos."""
        results = []
        
        for _, employee in base_df.iterrows():
            # Dados b√°sicos
            registration = employee['MATRICULA']
            union = employee['SINDICATO']
            admission_date = employee.get('Admiss√£o')
            vacation_days = int(employee['Dias_Ferias'])
            dismissal_date = employee.get('Data_Demissao')
            
            # Obter dias √∫teis para o sindicato
            base_days = self.calculation_engine.business_days_mapping.get(union, 22)
            
            # Calcular dias trabalhados
            days_worked = self.calculation_engine.calculate_days_worked(
                base_days=base_days,
                vacation_days=vacation_days,
                admission_date=admission_date,
                dismissal_date=dismissal_date,
                competence_month=competence_month,
                competence_year=competence_year
            )
            
            # Obter valor di√°rio
            daily_value = self.calculation_engine.get_daily_value(union)
            
            # Calcular valores finais
            total_value = days_worked * daily_value
            company_cost = total_value * 0.8
            professional_discount = total_value * 0.2
            
            # Criar registro
            result = {
                'Matricula': registration,
                'Admiss√£o': admission_date.strftime('%d/%m/%Y') if pd.notna(admission_date) else '',
                'Sindicato do Colaborador': union,
                'Compet√™ncia': f'01/{competence_month:02d}/{competence_year}',
                'Dias': days_worked,
                'VALOR DI√ÅRIO VR': daily_value,
                'TOTAL': round(total_value, 2),
                'Custo empresa': round(company_cost, 2),
                'Desconto profissional': round(professional_discount, 2),
                'OBS GERAL': self._generate_observations(employee, vacation_days, admission_date, dismissal_date)
            }
            
            results.append(result)
        
        return results
    
    def _generate_observations(self, employee: pd.Series, vacation_days: int, 
                             admission_date: Optional[datetime], dismissal_date: Optional[datetime]) -> str:
        """Gera observa√ß√µes para o registro."""
        observations = []
        
        if vacation_days > 0:
            observations.append(f"F√©rias: {vacation_days} dias")
        
        if pd.notna(admission_date):
            observations.append(f"Admiss√£o: {admission_date.strftime('%d/%m/%Y')}")
        
        if pd.notna(dismissal_date):
            observations.append(f"Demiss√£o: {dismissal_date.strftime('%d/%m/%Y')}")
        
        return "; ".join(observations)
    
    def generate_final_report(self, output_file: str = 'VR_MENSAL_AUTOMATIZADO.xlsx') -> str:
        """Gera o arquivo final no formato esperado."""
        if self.final_result is None:
            raise ValueError("Execute create_consolidated_base() primeiro!")
        
        self.logger.info(f"üìÑ Gerando arquivo final: {output_file}")
        
        # Garantir que o diret√≥rio existe
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Ordenar por matr√≠cula para melhor organiza√ß√£o
        self.final_result = self.final_result.sort_values('Matricula')
        
        # Salvar arquivo Excel
        try:
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                self.final_result.to_excel(writer, sheet_name='VR_Consolidado', index=False)
                
                # Adicionar planilha de estat√≠sticas se dispon√≠vel
                if self.processing_stats:
                    stats_df = pd.DataFrame([{
                        'M√©trica': 'Total de Colaboradores',
                        'Valor': self.processing_stats.total_collaborators
                    }, {
                        'M√©trica': 'Total de Dias',
                        'Valor': self.processing_stats.total_days
                    }, {
                        'M√©trica': 'Valor Total (R$)',
                        'Valor': f'{self.processing_stats.total_value:,.2f}'
                    }, {
                        'M√©trica': 'Custo Empresa (R$)',
                        'Valor': f'{self.processing_stats.company_cost:,.2f}'
                    }, {
                        'M√©trica': 'Desconto Profissional (R$)',
                        'Valor': f'{self.processing_stats.professional_discount:,.2f}'
                    }, {
                        'M√©trica': 'Colaboradores Exclu√≠dos',
                        'Valor': self.processing_stats.excluded_count
                    }, {
                        'M√©trica': 'Tempo de Processamento (s)',
                        'Valor': f'{self.processing_stats.processing_time:.2f}'
                    }])
                    
                    stats_df.to_excel(writer, sheet_name='Estat√≠sticas', index=False)
        
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao salvar arquivo: {e}")
            raise
        
        # Exibir estat√≠sticas
        if self.processing_stats:
            self.logger.info("üìä Estat√≠sticas do processamento:")
            self.logger.info(f"   ‚Ä¢ Colaboradores: {self.processing_stats.total_collaborators}")
            self.logger.info(f"   ‚Ä¢ Total de dias: {self.processing_stats.total_days}")
            self.logger.info(f"   ‚Ä¢ Valor total: R$ {self.processing_stats.total_value:,.2f}")
            self.logger.info(f"   ‚Ä¢ Custo empresa: R$ {self.processing_stats.company_cost:,.2f}")
            self.logger.info(f"   ‚Ä¢ Desconto profissional: R$ {self.processing_stats.professional_discount:,.2f}")
        
        self.logger.info(f"‚úÖ Arquivo salvo com sucesso: {output_file}")
        return output_file
    
    def validate_data(self) -> bool:
        """Executa valida√ß√µes completas nos dados processados."""
        if self.final_result is None:
            self.logger.warning("‚ùå Nenhum dado para validar")
            return False
        
        validations = self.validator.validate_processed_data(self.final_result)
        
        # Agrupar resultados por n√≠vel
        errors = [v for v in validations if v.level == ValidationLevel.ERROR]
        warnings = [v for v in validations if v.level == ValidationLevel.WARNING]
        info = [v for v in validations if v.level == ValidationLevel.INFO]
        
        # Exibir resultados
        self.logger.info("üîç Resultados da valida√ß√£o:")
        
        for validation in errors:
            self.logger.error(f"   ‚ùå {validation.message}: {validation.count} casos")
            if validation.details:
                self.logger.error(f"      Detalhes: {validation.details}")
        
        for validation in warnings:
            self.logger.warning(f"   ‚ö†Ô∏è  {validation.message}: {validation.count} casos")
            if validation.details:
                self.logger.warning(f"      Detalhes: {validation.details}")
        
        for validation in info:
            self.logger.info(f"   ‚úÖ {validation.message}")
        
        # Retornar True apenas se n√£o houver erros
        validation_passed = len(errors) == 0
        
        if validation_passed:
            self.logger.info("‚úÖ Todas as valida√ß√µes passaram com sucesso!")
        else:
            self.logger.error(f"‚ùå Valida√ß√£o falhou: {len(errors)} erros encontrados")
        
        return validation_passed
    
    def generate_summary_report(self) -> Optional[pd.DataFrame]:
        """Gera relat√≥rio resumido por sindicato."""
        if self.final_result is None:
            self.logger.warning("‚ùå Nenhum dado para gerar relat√≥rio")
            return None
        
        self.logger.info("üìà Gerando relat√≥rio resumido por sindicato...")
        
        try:
            summary = self.final_result.groupby('Sindicato do Colaborador').agg({
                'Matricula': 'count',
                'Dias': 'sum',
                'TOTAL': 'sum',
                'Custo empresa': 'sum',
                'Desconto profissional': 'sum',
                'VALOR DI√ÅRIO VR': 'mean'  # Valor m√©dio por sindicato
            }).round(2)
            
            # Renomear colunas para melhor legibilidade
            summary.columns = [
                'Qtd_Funcionarios', 
                'Total_Dias', 
                'Valor_Total', 
                'Custo_Empresa', 
                'Desconto_Funcionario',
                'Valor_Medio_Diario'
            ]
            
            # Adicionar coluna de valor m√©dio por funcion√°rio
            summary['Valor_Medio_Por_Funcionario'] = (
                summary['Valor_Total'] / summary['Qtd_Funcionarios']
            ).round(2)
            
            # Ordenar por valor total decrescente
            summary = summary.sort_values('Valor_Total', ascending=False)
            
            # Exibir resumo no log
            self.logger.info("üìä Resumo por sindicato (Top 10):")
            
            for sindicato, dados in summary.head(10).iterrows():
                sindicato_short = sindicato[:40] + "..." if len(sindicato) > 40 else sindicato
                self.logger.info(f"   üìã {sindicato_short}")
                self.logger.info(f"      ‚Ä¢ Funcion√°rios: {dados['Qtd_Funcionarios']}")
                self.logger.info(f"      ‚Ä¢ Dias: {dados['Total_Dias']}")
                self.logger.info(f"      ‚Ä¢ Valor Total: R$ {dados['Valor_Total']:,.2f}")
                self.logger.info(f"      ‚Ä¢ Valor M√©dio/Func: R$ {dados['Valor_Medio_Por_Funcionario']:,.2f}")
            
            if len(summary) > 10:
                self.logger.info(f"   ... e mais {len(summary) - 10} sindicatos")
            
            # Totais gerais
            total_funcionarios = summary['Qtd_Funcionarios'].sum()
            total_geral = summary['Valor_Total'].sum()
            
            self.logger.info("üìà Totais Gerais:")
            self.logger.info(f"   ‚Ä¢ Total de Funcion√°rios: {total_funcionarios}")
            self.logger.info(f"   ‚Ä¢ Valor Total Geral: R$ {total_geral:,.2f}")
            self.logger.info(f"   ‚Ä¢ N√∫mero de Sindicatos: {len(summary)}")
            
            return summary
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao gerar relat√≥rio resumido: {e}")
            return None
    
    def export_detailed_report(self, output_file: str) -> str:
        """Exporta relat√≥rio detalhado com m√∫ltiplas abas."""
        if self.final_result is None:
            raise ValueError("Execute create_consolidated_base() primeiro!")
        
        self.logger.info(f"üìã Exportando relat√≥rio detalhado: {output_file}")
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                # Aba 1: Dados consolidados
                self.final_result.to_excel(
                    writer, 
                    sheet_name='Dados_Consolidados', 
                    index=False
                )
                
                # Aba 2: Resumo por sindicato
                summary = self.generate_summary_report()
                if summary is not None:
                    summary.to_excel(writer, sheet_name='Resumo_Sindicatos')
                
                # Aba 3: Estat√≠sticas detalhadas
                if self.processing_stats:
                    detailed_stats = pd.DataFrame([
                        {'Categoria': 'Processamento', 'M√©trica': 'Total de Colaboradores', 'Valor': self.processing_stats.total_collaborators},
                        {'Categoria': 'Processamento', 'M√©trica': 'Colaboradores Exclu√≠dos', 'Valor': self.processing_stats.excluded_count},
                        {'Categoria': 'Processamento', 'M√©trica': 'Tempo de Processamento (s)', 'Valor': self.processing_stats.processing_time},
                        {'Categoria': 'Dias', 'M√©trica': 'Total de Dias', 'Valor': self.processing_stats.total_days},
                        {'Categoria': 'Dias', 'M√©trica': 'M√©dia de Dias por Funcion√°rio', 'Valor': round(self.processing_stats.total_days / self.processing_stats.total_collaborators, 2)},
                        {'Categoria': 'Valores', 'M√©trica': 'Valor Total (R$)', 'Valor': self.processing_stats.total_value},
                        {'Categoria': 'Valores', 'M√©trica': 'Custo Empresa (R$)', 'Valor': self.processing_stats.company_cost},
                        {'Categoria': 'Valores', 'M√©trica': 'Desconto Profissional (R$)', 'Valor': self.processing_stats.professional_discount},
                        {'Categoria': 'Valores', 'M√©trica': 'Valor M√©dio por Funcion√°rio (R$)', 'Valor': round(self.processing_stats.total_value / self.processing_stats.total_collaborators, 2)},
                    ])
                    detailed_stats.to_excel(writer, sheet_name='Estat√≠sticas_Detalhadas', index=False)
                
                # Aba 4: Detalhes de exclus√µes (se dispon√≠vel)
                if hasattr(self.exclusion_manager, 'exclusion_details'):
                    exclusion_data = []
                    for category, matriculas in self.exclusion_manager.exclusion_details.items():
                        for matricula in matriculas:
                            exclusion_data.append({
                                'Matricula': matricula,
                                'Categoria_Exclusao': category.title(),
                                'Motivo': f'Exclu√≠do por ser {category}'
                            })
                    
                    if exclusion_data:
                        exclusion_df = pd.DataFrame(exclusion_data)
                        exclusion_df.to_excel(writer, sheet_name='Detalhes_Exclus√µes', index=False)
        
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao exportar relat√≥rio detalhado: {e}")
            raise
        
        self.logger.info(f"‚úÖ Relat√≥rio detalhado exportado: {output_file}")
        return output_file
    
    def run_complete_process(self, 
                           files_folder: str, 
                           month: int = 5, 
                           year: int = 2025, 
                           output_file: Optional[str] = None) -> str:
        """
        Executa todo o processo de automa√ß√£o de forma integrada.
        
        Args:
            files_folder: Pasta contendo os arquivos Excel de entrada
            month: M√™s de compet√™ncia (1-12)
            year: Ano de compet√™ncia
            output_file: Arquivo de sa√≠da (opcional)
        
        Returns:
            Caminho do arquivo gerado
        """
        start_time = datetime.now()
        
        self.logger.info("üöÄ Iniciando Processo Completo de Automa√ß√£o VR")
        self.logger.info("=" * 60)
        self.logger.info(f"üìÖ Compet√™ncia: {month:02d}/{year}")
        self.logger.info(f"üìÇ Pasta de dados: {files_folder}")
        
        try:
            # Etapa 1: Carregamento de dados
            self.logger.info("üìÅ ETAPA 1: Carregamento de dados")
            self.load_data(files_folder)
            
            # Etapa 2: Processamento de dados
            self.logger.info("üßπ ETAPA 2: Processamento e limpeza")
            self.process_data()
            
            # Etapa 3: Consolida√ß√£o
            self.logger.info("üîÑ ETAPA 3: Consolida√ß√£o e c√°lculos")
            self.create_consolidated_base(month, year)
            
            # Etapa 4: Valida√ß√£o
            self.logger.info("üîç ETAPA 4: Valida√ß√£o dos dados")
            validation_passed = self.validate_data()
            
            if not validation_passed:
                self.logger.warning("‚ö†Ô∏è  ATEN√á√ÉO: Algumas valida√ß√µes falharam, mas o processo continuar√°")
            
            # Etapa 5: Gera√ß√£o de relat√≥rios
            self.logger.info("üìä ETAPA 5: Gera√ß√£o de relat√≥rios")
            
            # Definir arquivo de sa√≠da se n√£o informado
            if output_file is None:
                output_file = f'output/VR_MENSAL_{month:02d}_{year}.xlsx'
            
            # Gerar arquivo principal
            final_file = self.generate_final_report(output_file)
            
            # Gerar relat√≥rio resumido
            self.generate_summary_report()
            
            # Calcular tempo total
            total_time = (datetime.now() - start_time).total_seconds()
            
            # Resumo final
            self.logger.info("=" * 60)
            self.logger.info("‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!")
            self.logger.info("=" * 60)
            self.logger.info(f"‚è±Ô∏è  Tempo total: {total_time:.2f} segundos")
            self.logger.info(f"üìÑ Arquivo gerado: {final_file}")
            
            if self.processing_stats:
                self.logger.info(f"üë• Colaboradores processados: {self.processing_stats.total_collaborators}")
                self.logger.info(f"üí∞ Valor total: R$ {self.processing_stats.total_value:,.2f}")
            
            return final_file
            
        except Exception as e:
            error_time = (datetime.now() - start_time).total_seconds()
            self.logger.error("=" * 60)
            self.logger.error("‚ùå PROCESSO FALHOU!")
            self.logger.error("=" * 60)
            self.logger.error(f"‚è±Ô∏è  Tempo at√© erro: {error_time:.2f} segundos")
            self.logger.error(f"üö® Erro: {str(e)}")
            raise
    
    def get_processing_summary(self) -> Dict[str, Any]:
        """Retorna resumo completo do processamento."""
        if not self.processing_stats or self.final_result is None:
            return {"status": "No data processed"}
        
        summary = {
            "status": "completed",
            "processing_stats": {
                "total_collaborators": self.processing_stats.total_collaborators,
                "total_days": self.processing_stats.total_days,
                "total_value": self.processing_stats.total_value,
                "company_cost": self.processing_stats.company_cost,
                "professional_discount": self.processing_stats.professional_discount,
                "excluded_count": self.processing_stats.excluded_count,
                "processing_time": self.processing_stats.processing_time
            },
            "data_quality": {
                "total_records": len(self.final_result),
                "unique_unions": self.final_result['Sindicato do Colaborador'].nunique(),
                "date_range": {
                    "competence": self.final_result['Compet√™ncia'].iloc[0] if len(self.final_result) > 0 else None
                }
            },
            "file_status": {
                "loaded_files": len(self.raw_data),
                "failed_files": len(self.data_loader.failed_files),
                "failed_list": self.data_loader.failed_files
            }
        }
        
        return summary


# Fun√ß√£o de conveni√™ncia para uso direto
def run_vr_automation(files_folder: str, 
                     month: int = 5, 
                     year: int = 2025, 
                     output_file: Optional[str] = None) -> str:
    """
    Fun√ß√£o de conveni√™ncia para executar a automa√ß√£o VR de forma simples.
    
    Args:
        files_folder: Pasta contendo os arquivos Excel
        month: M√™s de compet√™ncia
        year: Ano de compet√™ncia  
        output_file: Arquivo de sa√≠da (opcional)
    
    Returns:
        Caminho do arquivo gerado
    """
    automation = VRAutomation()
    return automation.run_complete_process(files_folder, month, year, output_file)


if __name__ == "__main__":
    # Exemplo de uso direto
    try:
        result_file = run_vr_automation(
            files_folder="data",
            month=5,
            year=2025,
            output_file="output/VR_MAIO_2025.xlsx"
        )
        print(f"‚úÖ Processamento conclu√≠do: {result_file}")
    except Exception as e:
        print(f"‚ùå Erro no processamento: {e}")